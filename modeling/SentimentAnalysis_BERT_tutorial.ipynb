{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis를 통한 강의평 기반 강의 추천"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3uIMAjFnLg8E",
    "outputId": "e4a9e439-aa92-40db-9ba2-d9048a4a47d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3MB 30.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 40.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3MB 38.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
      "Collecting huggingface-hub==0.0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RfcyPcAALi57"
   },
   "outputs": [],
   "source": [
    "#주요 패키지들을 불러와줍니다.\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsWEQtuk_KId",
    "outputId": "94e673fb-2628-4057-a36a-297f7f424b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive/\n"
     ]
    }
   ],
   "source": [
    "#구글 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "uWXXy3JQLPmk"
   },
   "outputs": [],
   "source": [
    "#model 불러오기\n",
    "from sklearn.externals import joblib\n",
    "model = joblib.load('gdrive/MyDrive/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WjN3bdzuLT6K"
   },
   "outputs": [],
   "source": [
    "def convert_data(sent):\n",
    "  global final_test_sentence\n",
    "  # tokenize and pad sentence\n",
    "  sentence = [\"[CLS] \" + str(sent) + \" [SEP]\"]\n",
    "  tokenized_texts = [tokenizer.tokenize(sentence[0])]\n",
    "  labels = [1] #1로 고정, 상관 없음\n",
    "  input_ids = [tokenizer.convert_tokens_to_ids(tokenized_texts[0])]\n",
    "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "  #attention_masks\n",
    "  attention_masks = []\n",
    "  for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "  #파이토치 텐서로 변환\n",
    "  test_inputs = torch.tensor(input_ids)\n",
    "  test_labels = torch.tensor(labels)\n",
    "  test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "  #배치 및 데이터로더 설정\n",
    "  test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "  test_sampler = RandomSampler(test_data)\n",
    "  input_data = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)\n",
    "  return input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "l58LVGoLLUWp"
   },
   "outputs": [],
   "source": [
    "def test_sentence(input_data):\n",
    "  # 평가모드로 변경\n",
    "  model.eval()\n",
    "\n",
    "  # 변수 초기화\n",
    "  eval_loss, eval_accuracy = 0, 0\n",
    "  nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "  # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "  for step, batch in enumerate(input_data):\n",
    "      # 배치를 GPU에 넣음\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "      \n",
    "      # 배치에서 데이터 추출\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "      \n",
    "      # 그래디언트 계산 안함\n",
    "      with torch.no_grad():     \n",
    "          # Forward 수행\n",
    "          outputs = model(b_input_ids, \n",
    "                          token_type_ids=None, \n",
    "                          attention_mask=b_input_mask)\n",
    "      \n",
    "      ###################### get prediction! ######################\n",
    "      logits = outputs[0]\n",
    "\n",
    "      # CPU로 데이터 이동\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "      pred = np.argmax(logits)\n",
    "      if pred == 1:\n",
    "        result = \"긍정\"\n",
    "      elif pred == 0:\n",
    "        result = \"부정\"\n",
    "      \n",
    "      print(sentence, \"\\n위 문장은 \" + result + \"입니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R5gIk4LFA_Wz",
    "outputId": "c1059dbe-1684-4b5c-f079-ec4adba2144e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "#GPU 체크 및 할당\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "BTeafcLsLav1"
   },
   "outputs": [],
   "source": [
    "#토크나이저, MAX_LEN, BATCH_SIZE 정의\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7-9bcK1kCeLh",
    "outputId": "3f9d1436-d5a8-4b88-b618-158078659124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코로나 이후 비대면으로 강의가 전환되었는데도 불구하고 교수님께서 강의 준비를 꼼꼼히 해주시고 학생들도 신경 써 주시는 것 같아요. \n",
      "위 문장은 긍정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"코로나 이후 비대면으로 강의가 전환되었는데도 불구하고 교수님께서 강의 준비를 꼼꼼히 해주시고 학생들도 신경 써 주시는 것 같아요.\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oD0ehsJiAK8z",
    "outputId": "e06ea9dd-3eed-4cbf-e83e-2a1b7a3d49c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교수님 목소리가 너무 작고 강의력이 별로 안좋으신 것 같아요. 사실 수업에서 뭘 배우는지 잘 모르겠어요. \n",
      "위 문장은 부정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"교수님 목소리가 너무 작고 강의력이 별로 안좋으신 것 같아요. 사실 수업에서 뭘 배우는지 잘 모르겠어요.\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rr4iTmBKCRRC",
    "outputId": "0e320049-1d0a-459a-d2e2-6da90a0ac014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "힘들었지만 얻어가는 게 있었던 것 같아요. \n",
      "위 문장은 긍정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"힘들었지만 얻어가는 게 있었던 것 같아요.\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tf6_3HYrCY6A",
    "outputId": "085b72aa-3f87-44ac-8db1-f991ebc55071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교수님은 강의력 나쁘지 않고 괜찮으셨던 것 같은데 성적을 너무 낮게 주시는 것 같아요. 이 점 참고하셔서 들으셔야 할 것 같아요. \n",
      "위 문장은 부정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"교수님은 강의력 나쁘지 않고 괜찮으셨던 것 같은데 성적을 너무 낮게 주시는 것 같아요. 이 점 참고하셔서 들으셔야 할 것 같아요.\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kH1FX6mEClnD",
    "outputId": "7bbb40eb-8b23-409e-c334-3603d3b552e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "과제가 별로 없어서 수업 듣기 수월했습니다 \n",
      "위 문장은 긍정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"과제가 별로 없어서 수업 듣기 수월했습니다\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EQkfi7PCrm4",
    "outputId": "3b7a73b1-7854-4931-b5c2-93a97e2ad4e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체적으로 무난했는데 교수님 성적 기준이 뭔지 모르겠어요 \n",
      "위 문장은 부정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"전체적으로 무난했는데 교수님 성적 기준이 뭔지 모르겠어요\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpB7l_3DCoD-",
    "outputId": "6903521c-fe2f-411a-d894-12fb1e19ebf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "일단 수업 듣는 내내 좋은 점은 딱 하나 있었던 것 같습니다. 할 게 별로 없었어요. 성적에 비해서 시키시는 것도 별로 없으시구요. 그런데 저는 개인적으로 수업 들을 때 조금 힘들어도 얻는 게 많은 수업들을 좋아하는데 이 수업은 저랑 안 맞았어요. 얻어가는 게 하나도 없는 수업이라고 생각하시면 됩니다. 과제같은 것들도 의미가 없게 느껴져서 수업 듣는 내내 너무 힘들었습니다. \n",
      "위 문장은 부정입니다.\n"
     ]
    }
   ],
   "source": [
    "# 직접 문장을 넣어서 확인할 수 있는 코드입니다.\n",
    "sentence = \"일단 수업 듣는 내내 좋은 점은 딱 하나 있었던 것 같습니다. 할 게 별로 없었어요. 성적에 비해서 시키시는 것도 별로 없으시구요. \\\n",
    "그런데 저는 개인적으로 수업 들을 때 조금 힘들어도 얻는 게 많은 수업들을 좋아하는데 이 수업은 저랑 안 맞았어요. 얻어가는 게 하나도 없는 수업이라고 생각하시면 됩니다. \\\n",
    "과제같은 것들도 의미가 없게 느껴져서 수업 듣는 내내 너무 힘들었습니다.\"\n",
    "test_sentence(convert_data(sentence))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "loadmodel_bert_andTest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
